\documentclass{article} % For LaTeX2e
\usepackage{nips11submit_e,times}
\usepackage{graphicx}
%\documentstyle[nips10submit_09,times,art10]{article} % For LaTeX 2.09


\title{Modeling Fly Trajectories to Automatically Detect Mutations}


\author{
Joseph Marrama \\
Department of Symbolic Systems\\
Stanford University\\
\texttt{jmarrama@stanford.edu} \\
\And
Alden Timme \\
Department of Math and Computational Sciences \\
Stanford University \\
\texttt{aotimme@stanford.edu} \\
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

%is an abstract necessary?
%\begin{abstract}
%\end{abstract}



\section{Introduction}
%a bit on the problem at hand... not too long

In biological experiments involving flies, making sure all the flies that are assumed to be normal actually are healthy wildtype flies is of the utmost importance. There have been previous studies on normal and mutated flies that suggest there is a way to automatically classify flies as normal or not given measurements of their movements. These studies have produced a great deal of observational data of fly movements as well. In our project, we use this data to develop a model that performs reasonably well on automatically classifying flies as healthy or mutated.


\section{Related Work}
%what the fuck? are you serious? i've certainly read a fuckload about classifying flies, give me a goddamn break daphne
%the project guidelines says we have to put this in.....


\section{Our models}
%uh...... i guess we explain our models here? The guidelines say to include a section about 'our implementation', so i guess this is it. 

%Question: different subsection for different models and then present their performances in 'results', or should we just go through chronologically what we tried and how we iterated through better and better models, presenting the results of each one after its description?

The data in this project is presented as a set of measurements along a number of trajectories of walking flies. We are presented with trajectories for both wild type (normal) flies and for mutated flies. Along these trajectories we are provided a number of measurements, taken at intervals of $1/30$ of a second. These measurements are translational velocity in the forward direction (VT), translational velocity in the sideways direction (VS), rotational velocity (VR), the fly orientation (PO), the fly position along the x-axis (PX), and the fly position along the y-axis (PY). The other important data are the stimulation pulses. There are two types of motion stimuli, corresponding to coherent random dot motion in one direction ($S_1$) and coherent random dot motion in the opposite direction ($S_2$). $S_1$ and $S_2$ are presented in pulses that last either 4 or 5 time steps (where a time step is $1/30$ of a second), and when no stimulus is applied there is a constant noise of random, incoherent dot motion. In addition, these experiments were carried out in 3 different conditions. The three conditions are ‘decrement’, in which dark dots are presented over a bright background; ‘increment’, in which bright dots are presented over a dark background; and ‘dark’, in which noise was replaced by a medium light level and the only stimulus was a dark pulse (complete darkness).

Because this data belongs to a time series, our approach was to design a temporal probabilistic graphical model to model the trajectories of the wild type flies. After training a model on normal flies, we use it to identify wild-type or mutant flies by assigning a log-likelihood to a trajectory (given the model) and assuming that a fly is mutant if the log-likelihood is too low and is wild-type if the log-likelihood is high enough. However, because the trajectories are of different lengths (trajectories last from 20 up to 200 time steps), we choose as our metric the log-likelihood of the trajectory divided by the length of the trajectory (the trajectory’s average log-likelihood). We use the average log-likelihood for identifying wild-type and mutant flies by using a validation data set (of wild-type and mutant flies) to find the best average log-likelihood cut-off. Anything below this cut-off is determined to be mutant and everything above is wild-type. The best average log-likelihood cut-off is the average log-likelihood that maximizes the F1 score,
\begin{eqnarray*}
F_1 &=& \frac{2\cdot precision \cdot recall}{precision + recall}\\
precision &=& \frac{tp}{tp + fp}\\
recall &=& \frac{tp}{tp + fn}
\end{eqnarray*}
where $tp$ is the number of true positives, $fp$ is the number of false positives, and $fn$ is the number of false negatives.

The data on fly positions (PX and PY) were confounding because they were not calibrated, so our models considers only the velocities, VT, VS, and VR, the orientation, PO, and the stimuli, $S_1$ and $S_2$. The first few measurements on each trajectory are very obviously way off, so we throw out the first 6 time steps of each trajectory. We also need a way to represent the stimuli in our model. Although the stimuli are applied in pulses, there is evidence showing that the effects of the pulses on the flies will last a few time steps after the pulse ends (REF). However, we do not expect the stimulus to affect the fly many time steps after the last pulse, so we parameterize the variables $S_1$ and $S_2$ (corresponding to the two stimulus types) by the amount of time since the beginning of the most recent pulse. The value 1 corresponds to the beginning of a new pulse, and at each time step thereafter will be $2, 3, \ldots$ until reaching a maximum value of $M$ (the fly has limited memory after all). Once we are past M time steps after the pulse, the value of $S_i$ ($i=1,2$) is $0$. This way of encoding the stimulus allows the model to take into account an M-order Markovity of the time series.

Our first model is a baseline model, where each variable at a given time-step $\tau$ is dependent only on the same variable at the time-step $\tau-1$ and the stimuli $S_1, S_2$ at the current time step $\tau$ (FIGURE 1). The probability distributions are parameterized by linear Gaussians,
$$
P(X^{\tau} = x^{\tau} | X^{\tau-1}=x^{\tau-1}, S_1, S_2) \sim \mathcal{N}\left( \theta_{x,0} + \theta_{x,1}S_1 + \theta_{x,2}S_2 + \theta_{x,3}x^{\tau-1}, \; \sigma_x \right)
$$
where $X^{\tau}$ is one of the four observed variables at time step $\tau$.
However, because the orientation variable (PO) takes on values in $[-\pi,\pi]$, this model can run into problems in the region around $-\pi$ and $\pi$, which are the same orientation but have very different parameterizations. To deal with this, we split up the orientation variable into the cosine and sine of the variable (cO and sO, respectively), and connect cO and sO at each time step to both cO and sO at the next time step (FIGURE ??).

We also try a fully connected model in which every observed variable at time step $\tau$ (except the stimulus variables) is distributed according to a linear Gaussian, where the mean is a linear combination of all the observed variables at time $\tau-1$ (except the stimuli) and the stimuli variable at time $\tau$ and the variance depends only on the variable (FIGURE - all of these should probably just be together in one spot...). We try this both with the orientation variable left as is and with the orientation variable split into its sine and cosine (again, FIGURE, with the rest).

Finally, we have one more model which makes use of hidden variables. In this model, all of the observed variables (i.e. measurements) at each time step depend only on a hidden variable in that time step. This hidden variable $Z$ depends on the hidden variable at the previous time step and the stimuli at the current time step. For each pair $(S_1,S_2)$, we learn a transition matrix from each state $z$ to every other state $z’$. The observed variables at each time step are distributed normally with a mean and variance depending on the hidden state (FIGURE!!). The motivation for this model is that flies will often initiate a “move” that will last a number of time steps. This move is probably based on the fly’s previous move and the stimuli, so we use the hidden variable as a way of trying to encode a fly’s move.

\includegraphics[width=3.5cm]{simple.jpg}\includegraphics[width=3.5cm]{full.jpg}\includegraphics[width=3.5cm]{simple-sincos.jpg}\includegraphics[width=3.5cm]{full-sincos.jpg}\\
\small{From left to right: (a) simple connected model, (b) fully-connected model, (c) simple connected model with orientation split into $sin$ and $cos$, and (d) fully-connected model with orientation split into $sin$ and $cos$} % have to figure out where to put this figure...

We use the Expectation-Maximization Algorithm to learn the parameters for the hidden model. In order to learn the expected sufficient statistics during the E-step, we tried exact and approximate inference techniques. To infer exactly, we use a variant of the forward-backward equations commonly used to learn hidden Markov models (HMMs) to efficiently provide a distribution over all possible hidden state sequences for each trajectory (EQUATIONS ??). For approximate inference, we used the technique of particle filtering, sending about 1000 particles through each trajectory to obtain an approximate distribution over state sequences for the trajectory.

\section{Results}
%see my question above


\section{Discussion}
%smallden is in the dept. of ball sucking, LOL


\end{document}
